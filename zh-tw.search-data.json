{"/about/":{"data":{"":"Hextra is designed to be a simple, fast, and flexible theme for building modern static websites. It is especially well-suited for documentation websites but can also be used for various types of sites, such as blogs, portfolios, and more.\nHugo, like Jekyll, is a static site generator. What sets Hugo apart is that it is a single binary, making it easy to install and run on various platforms. It is also extremely fast and reliable, capable of rendering a site with thousands of pages in milliseconds.\nHextra is built with a mindset focused on having a minimal footprint. To get started, no extra dependencies like Node.js packages are required; all you need is a single YAML configuration file, along with your Markdown content. Thus, we can focus on writing quality content instead of setting up tooling.","credits#Credits":"Hextra cannot be built without the following tools and inspirations:\nHugo Tailwind CSS Heroicons Nextra Next.js "},"title":"關於我"},"/docs/":{"data":{"":"👋 尼好，歡迎來看我的","features#Features":" Beautiful Design - Inspired by Nextra, Hextra utilizes Tailwind CSS to offer a modern design that makes your site look outstanding. Responsive Layout and Dark Mode - It looks great on all devices, from mobile, tablet to desktop. Dark mode is also supported to accommodate various lighting conditions. Fast and Lightweight - Powered by Hugo, a lightning-fast static-site generator housed in a single binary file, Hextra keeps its footprint minimal. No JavaScript or Node.js are needed to use it. Full-text Search - Built-in offline full-text search powered by FlexSearch, no additional configuration required. Battery-included - Markdown, syntax highlighting, LaTeX math formulae, diagrams and Shortcodes elements to enhance your content. Table of contents, breadcrumbs, pagination, sidebar navigation and more are all automatically generated. Multi-language and SEO Ready - Multi-language sites made easy with Hugo’s multilingual mode. Out-of-the-box support is included for SEO tags, Open Graph, and Twitter Cards. ","what-is-hextra#What is Hextra?":"Hextra is a modern, fast and batteries-included [Hugo][hugo] theme built with [Tailwind CSS][tailwind-css].\nDesigned for building beautiful websites for documentation, blogs, and websites, it provides out-of-the-box features and flexibility to meet various requirements."},"title":"Blog"},"/docs/kubernetes/":{"data":{"":"Explore the following sections to learn how to use Hextra:\n在正式環境上踩到 StatefulSet 的雷，拿到 P1 的教訓 部署 Pod 遇到 container veth name provided (eth0) already exists 錯誤 "},"title":"Kubernetes"},"/docs/kubernetes/k8s-statefulset-podmanagementpolicy/":{"data":{"":"此文章要來記錄一下前陣子在公司的正式環境踩到 StatefulSet 的雷，事情是這樣的，我們有些服務，是使用 StatefulSet 來建置，至於為什麼不用 Deployment，這個說來話長 (也不是因為需要特定的 Pod 名稱、或是網路標記等等)，我們這邊先不討論，這個 StatefulSet 服務是 Nginx + PHP-FPM，為了避免流量進入到 processes 已經被用光的 Pod 中，我們在 StatefulSet 的 PHP Container 上有設定 readiness，readiness 的設定長得像以下：\nreadinessProbe: exec: command: - \"/bin/bash\" - \"-c\" - | CHECK_INFO=$(curl -s -w 'http code:\\t%{http_code}\\n' 127.0.0.1/status) HTTP_CODE=$(echo -e \"${CHECK_INFO}\" | awk '/http code:/ {print $3}') IDLE_PROCESSES=$(echo -e \"${CHECK_INFO}\" | awk '/idle processes:/ {print $3}') [[ $HTTP_CODE -eq 200 \u0026\u0026 $IDLE_PROCESSES -ge 10 ]] || exit 1 我們會用 curl 來打 /status，檢查回傳的 http code 是否為 200，以及 idle processes 是否大於等於 10，如果不符合，就會回傳 1，讓他被標記不健康，讓 Kubernetes 停止流量到不健康的容器，以確保流量被路由到其他健康的副本。","參考資料#參考資料":"Kubernetes — 健康檢查：https://medium.com/learn-or-die/kubernetes-%E5%81%A5%E5%BA%B7%E6%AA%A2%E6%9F%A5-59ee2a798115\nPod Management Policies：https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies","問題#問題":"當天遇到的情況是，我們上程式後，Pod 都一切正常，當流量開始進來後，發現 10 個 Pod 會開始偶發的噴 Readiness probe failed，查看監控發現 processes 越來越低，最後被反應服務有問題，我們查看 Hpa 的紀錄的確有觸發到 40 個 Pod，只是查看 Pod 數還是依樣卡在 10 個，當下我們有嘗試使用調整 yaml 在 apply，發現 StatefulSet 的 yaml 也已經更新了，但 Pod 還是一樣卡在 10 個，也有使用 kubectl 下 kubectl scale sts [服務名稱] --replicas=0，想要切換 Pod 數也沒有辦法。\n當下我們有先 Call Google 的 Support 一起找原因，Google 是建議我們 readiness 的條件不要設的太嚴格，可以加上 timeoutSeconds: 秒數，但對於 Pod 卡住，還是沒有找到原因，後來我們查了一下 StatefulSet 的文件發現，StatefulSet 有一個設定 podManagementPolicy，預設是 OrderedReady，他必須等待前面的 Pod 是 Ready 狀態，才會再繼續建立新的，也就是說我們的 StatefulSet 已經卡住，導致就算 Hpa 觸發要長到 40 個 Pod 也沒有用。","測試結果#測試結果":"最後我們就使用兩種模式來測試看看，已下是測試結果(透過 P1 才知道的設定ＱＱ)：\n有將測試的 StatefulSet 放在 Github，可以點我查看 (可以調整 readinessProbe 的 httpGet.Path 故意把他用壞)\n使用 OrderedReady 模式 StatefulSet 在 podManagementPolicy 預設 OrderedReady 的模式，故意讓 readiness 卡住時 (Pod 卡住時)：\n當下的 StatefulSet 設定： StatefulSet 設定 Pod 狀態： Pod 狀態 使用指令調整 Pod 數量 我們這時候下指令調整 Pod 數量，看看會發生什麼事：\nkubectl scale sts my-statefulset --replicas=5 我們先看 StatefulSet 的 yaml 可以看到 Pod replicas 已經改變，也可以看 generation 有更新，代表 StatefulSet 本身有接收到調整設定的請求。\n下指令調整後的 StatefulSet 設定 看了一下 Pod 數量，也是一樣卡住，且 Pod 數量也沒有變化。\n下指令調整後的 Pod 狀態 使用 yaml 調整 Pod 數量 我們直接調整 StatefulSet yaml 的 Pod 數量，看看會發生什麼事：\n一樣我們先看 StatefulSet 的 yaml 可以看到 Pod replicas 已經改變(這裡應該切別的 Pod 數量，切回 3 個好像沒有意義 xD)，也可以看 generation 有更新。\n使用 yaml 調整後的 StatefulSet 設定 看了一下 Pod 數量，也是一樣卡住，且 Pod 數量也沒有變化。\n使用 yaml 調整後的 Pod 狀態 所以代表在 OrderedReady 的模式下，Pod 卡住時，無法對 Pod 進行任何操作，必須要手動刪除卡住的 Pod 才吃得到最新的設定。\n使用 Parallel 模式 StatefulSet 在 podManagementPolicy Parallel 的模式，故意讓 readiness 卡住時 (Pod 卡住時)：\n當下的 StatefulSet 設定： StatefulSet 設定 Pod 狀態： Pod 狀態 使用指令調整 Pod 數量 我們這時候下指令調整 Pod 數量，看看會發生什麼事：\nkubectl scale sts my-statefulset --replicas=5 我們先看 StatefulSet 的 yaml 可以看到 Pod replicas 已經改變，也可以看 generation 有更新，代表 StatefulSet 本身有接收到調整設定的請求。\n下指令調整後的 StatefulSet 設定 看了一下 Pod 數量，就算 my-statefulset-2 卡住，還是可以擴到 5 個 Pod。\n下指令調整後的 Pod 狀態 使用 yaml 調整 Pod 數量 我們直接調整 StatefulSet yaml 的 Pod 數量，看看會發生什麼事：\n一樣我們先看 StatefulSet 的 yaml 可以看到 Pod replicas 已經改變，也可以看 generation 有更新。\n使用 yaml 調整後的 StatefulSet 設定 看了一下 Pod 數量，也不會管其他 Pod 是否 Ready，一樣可以縮小成 2 個 Pod。\n使用 yaml 調整後的 Pod 狀態 ","結論#結論":"後來我們重新檢查了一下為什麼 processes 會用完，結果發現是 RD 的程式邏輯，導致每筆 Request 必須等待前一筆 Request 做完，才會開始動作，讓 processes 一直被占用，沒辦法即時消化，導致 processes 用完，又加上服務是使用 StatefulSet，預設模式的 OrderedReady，必須等待前一個 Pod 是 Ready 才可以自動擴縮，所以當我們 Hpa 想要擴縮，來增加可用的 processes 數量，也因為沒辦法擴縮，最後導致這一連串的問題 😕。\n另外，如果想要從 OrderedReady 模式切成 Parallel 模式 (反正過來也是)，必須先將原本的 StatefulSet 給刪除，才可以調整：\nOrderedReady 模式切成 Parallel 模式 ","解決辦法#解決辦法":"當下想趕快解決 readiness 這個問題，調整 timeoutSeconds 後，單純 apply 是沒有用的，要記得刪掉卡住的 Pod，讓他重新建立，才會套用新的設定 (但我們當下太在意為甚麼 Pod 會卡住，沒有想到要先把 readiness 問題修掉 xD，我們當下的解法是先將流量導到地端正常的服務上)。\n另外 Google 也說，假如我們還是必須使用 StatefulSet 來建立服務，建議我們把 podManagementPolicy 改成 Parallel，它會有點像是 Deployment 的感覺，不會等待其他 Pod 變成 Ready 狀態，所以可以讓我們就算在 readiness 卡住的情況下，也可以自動擴縮服務。\nStatefulSet podManagementPolicy 參數說明\nOrderedReady (預設) Pods 會按照順序一個接一個地被創建。即，n+1 號 Pod 不會在 n 號 Pod 成功創建且 Ready 之前開始創建。 在縮小 StatefulSet 的大小時，Pods 會按照反向順序一個接一個地被終止。即，n 號 Pod 不會在 n+1 號 Pod 完全終止之前開始終止。 這確保了 Pods 的啟動和終止的順序性。\nParallel 所有 Pods 會同時地被創建或終止。 當 StatefulSet 擴展時，新的 Pods 會立即開始創建，不用等待其他 Pods 成為 Ready 狀態。 當縮小 StatefulSet 的大小時，要終止的 Pods 會立即開始終止，不用等待其他 Pods 先終止。 這種策略提供了快速的擴展和縮小操作，但缺乏順序性保證。"},"title":"正式環境上踩到 StatefulSet 的雷，拿到 P1 的教訓"},"/docs/kubernetes/pod-veth-name-provided-eth0-already-exists/":{"data":{"":"此文章要來記錄一下公司同事在正式服務上遇到的問題，會詳細說明遇到事情的經過，以及開單詢問 google support 最後討論出的暫時解決的辦法：\n簡單列出正式站當下服務環境：\ngke master version：1.25.10-gke.2700 gke node version：1.25.8-gke.1000 該問題發生的 node pool 有設定 taint 發生問題的 Pod 是用 Statefulset 建立的服務 ","事情發生的經過#事情發生的經過":" RD 同仁反應，發現使用 Statefulset 建立的排程服務有問題，下 kubectl delete 指令想要刪除 Pod，讓 Pod 重新長，卻卡在 Terminating，等待一段時間後，決定下 kubectl delete --force --grace-period=0 來強制刪除 Pod，這時候狀態會卡在 ContainerCreating，使用 Describe 查看，會出現以下錯誤： Warning (combined from similar events): Failed to create pod sandbox: rpo error: code = Unknown desc = failed to setup network for sandbox \"14fe0cd3d688aed4ffed4c36ffab1a145230449881bcbe4cac6478a63412b0c*: plugin type=*gke\" failed (add): container veth name provided (etho) already exists 我們 SRE 協助查看後，也有嘗試去下 kubectl delete --force --grace-period=0 來刪除 Pod，但還是一樣卡在 ContainerCreating，最後是先開一個新的 Node 並讓該 Pod 建立到新的 Node 上，才解決問題。為了方便 google support 協助檢查出問題的 Node，先將 Node 設定成 cordon，避免其他 Pod 被調度到該問題 node 上。 Node 設定成 cordon\nNode 可以設定 cordon、drain 和 delete 三個指定都會使 Node 停止被調度，只是每個的操作暴力程度不同：\ncordon：影響最小，只會將 Node 標示為 SchedulingDisabled 不可調度狀態，但不會影響到已經在該 Node 上的 Pod，使用 kubectl cordon [node name] 來停止調度，使用 kubectl uncordon [node name] 來恢復調度。\ndrain：會先驅逐在 Node 上的 Pod，再將 Node 標示為 SchedulingDisabled 不可調度狀態，使用 kubectl drain [node name] --ignore-daemonsets --delete-local-data 來停止調度，使用 kubectl uncordon [node name] 來恢復調度。\ndelete：會先驅逐 Node 上的 Pod，再刪除 Node 節點，它是一種暴力刪除 Node 的作法，在驅逐 Pod 時，會強制 Kill 容器進程，沒辦法優雅的終止 Pod。\n我們隨後開單詢問 goolge support。 ","參考#參考":"Node 節點禁止調度（平滑維護）方式- cordon，drain，delete：https://www.cnblogs.com/kevingrace/p/14412254.html","與-google-support-討論內容#與 Google Support 討論內容":"Google Support 經過查詢後，回覆說：這個問題是因為 Pod 被強制刪除導致，強制刪除是一種危險的操作，不建議這樣處理，下面有詳細討論。\n一開始卡在 Terminating 狀態，我們也有請 RD 說明一下當下遇到的問題以及處理動作：RD 當時想要刪除 Pod 是因為該程式當下有 Bug，將 redis 與 db 連線給關閉，程式找不到就會一直 retry，導致相關進程無法結束，再加上 terminationGracePeriodSeconds 我們設定 14400，也就是 4 小時，才會卡在 Terminating 狀態。 (terminationGracePeriodSeconds 設定這麼久是希望如果有被 on call，工程師上來時，可以查看該 Pod 的錯誤原因)\n因為卡在 Terminating 太久，RD 有執行 kubectl delete --force，就是因為下了 --force 才造成相關資源問題 (例如 container proccess, sandbox, 以及網路資源)沒有刪乾淨。所以引起了此次的報錯 “container veth name provided (eth0) already exists”。 (因為我們服務使用 Statefulset，Pod 名稱相同，導致 eth0 這個網路資源名稱重複，所以造成錯誤，可以用 deployment 來改善這個問題，只是資源如果沒有清理乾淨會佔用 IP，所以單純調整成 deployment 也不是最佳解)\nGoogle 產品團隊建議，如果 Pod 處於 Running 狀態時，想要快速刪除 Pod 時，一開始就先使用 kubectl delete pod --grace-period=number[秒數] 來刪除，如果已經是 Terminating 狀態則無效。(SRE 同仁已測試過，與 Google Support 說明相同)\n那如果已經處於 Terminating 狀態，要怎麽讓 Pod 被順利刪除，這部分 Google Support 後續會在測試並給出建議，目前測試是：進去卡住的 Pod Container，手動刪除主進程 (pkill) 就可以了。\nGoogle Support 回覆 "},"title":"部署 Pod 遇到 container veth name provided (eth0) already exists 錯誤"},"/docs/nginx/":{"data":{"":"Explore the following sections to learn how to use Hextra:\n想使用 Nginx Upstream Proxy 到外部服務，並帶入對應的 header 該怎麼做？ Soketi WebSocket Server LOG 不定時出現 502 error 以及 connect() failed (111: Connection refused) "},"title":"Nginx"},"/docs/nginx/nginx-upstream-set-host-header/":{"data":{"":"此文章要來記錄一下最近在公司服務入口遇到的一些小問題，以及解決的方法。簡單說明一下，我們的服務入口是用 Nginx 來當作 proxy server，將不同路徑或是 servername 導到對應的後端程式，或是外部的服務上(例如 AWS cloudfront.net)，本篇要測試的是如果使用要同時使用 upstream 到外部服務，且需要帶 host header 該怎麼做。\nNginx 的 upstream 是什麼？\n通常我們 proxy_pass 的寫法會是這樣：\nlocation /aaa { proxy_pass http://aaa.example.com; } 當 Nginx 收到的 request 是 /aaa 時，就會將 request 轉發到 http://aaa.example.com。\n但假如後端有多台機器或是服務，可以處理同一種 request，這時候就可以使用 upstream 來處理：\nupstream backend_hosts { server aaa.example.com; server bbb.example.com; server ccc.example.com; } location /aaa { proxy_pass http://backend_hosts; } 這樣子的好處是可以有多個機器或是後端服務可以分散請求，做到負載平衡的效果。","參考#參考":"Make nginx to pass hostname of the upstream when reverseproxying：https://serverfault.com/questions/598202/make-nginx-to-pass-hostname-of-the-upstream-when-reverseproxying","問題#問題":"那如果我們使用 Nginx upstream 時，還想要同時帶 host 的 header 到後端該怎麼做呢？我們先來看一下目前的寫法：\n( 測試範例是使用 docker 來模擬，可以參考程式碼 \u003e 點我前往 github，會有三個 nginx，其中一個是負責 proxy 的 nginx 名為 proxy，另外兩台是 upstream 後的服務，名為 upstream_server1、upstream_server2 )\nnginx-old.conf upstream upstream_server { server upstream_server1; server upstream_server2; } server { listen 80; server_name localhost; location /upstream_server/ { proxy_pass http://upstream_server; proxy_set_header Host \"upstream_server1\"; proxy_set_header Host \"upstream_server2\"; access_log /var/log/nginx/access.log upstream_log; } } } 可以看到我們希望 Nginx 收到 request 是 /upstream_server 時，將 request 轉發到 http://upstream_server，而 upstream_server 後面有兩個 server，並且在 proxy 時，帶入兩個不同的 host header。但如果真的這樣寫，可以達到我們想要得效果嗎？我們實際跑看看程式 (範例可以使用 nginx-old.conf)：\nnginx 原本寫法 從上面的 LOG 可以發現，我們 call /upstream_server 時，後端的 upstream_server1、upstream_server2 收到的 host 只會收到第一個設定的 Host，且服務會出現 400 Bad Request，查了一下網路文章，發現出現 400 Bad Request，可能跟 header 送太多資訊過去，詳細可以參考 解決網站出現 400 Bad Request 狀態的方法。\n這邊推測應該是後端如果也是用 nginx 直接接收才會遇到 400 的問題，還好目前公司服務還是正常的 xDD，檢查一下後發現，其實後端根本沒有要求對應 header 才能接收(應該是對方忘記加上此限制)。","解決#解決":"好，不管是否需要對應 header，我們還是找看看有沒有辦法同時使用 upstream，並帶入對應 host 的方法呢？\n最後參考網路上的文章，似乎只能使用兩層的 proxy，才能完成這兩個需求，我們來看看要怎麼寫吧 (範例可以使用 nginx.conf)：\nnginx.conf server { listen 777; server_name localhost; location / { proxy_pass http://upstream_server1; proxy_set_header Host \"upstream_server1\"; access_log /var/log/nginx/access.log upstream_log; } } server { listen 888; server_name localhost; location / { proxy_pass http://upstream_server2; proxy_set_header Host \"upstream_server2\"; access_log /var/log/nginx/access.log upstream_log; } } upstream upstream_server { server 127.0.0.1:777; server 127.0.0.1:888; } server { listen 80; server_name localhost; location /upstream_server/ { proxy_pass http://upstream_server; access_log /var/log/nginx/access.log upstream_log; } } 可以看到上面的程式碼，我們透過兩層的 proxy，來達到我們想要的效果，這樣子就可以同時使用 upstream，並且帶入對應的 host header。\n首先在 28 ~ 36 行，我們一樣如果 Nginx 收到 request 是 /upstream_server 時，會 proxy 到 upstream_server 這個 upstream 中，而 upstream_server 有兩個 server，分別是 127.0.0.1:777、127.0.0.1:888，但實際上沒有這兩個 port，所以我們需要再寫一層一般的 proxy 設定，分別是 1 ~ 10 行、12 ~ 21 行，這樣子就可以達到我們想要的效果。\n但這個方法比較適用於 upstream 後端沒有太多個服務或是機器的情況，如果有很多個服務或是機器，就需要寫很多的 proxy，這樣子會變得很麻煩，所以如果有更好的方法，也歡迎留言跟我分享 🤣。\n最後我們來看一下實際執行的結果：\n使用多層的 nginx proxy 處理 "},"title":"想使用 Nginx Upstream Proxy 到外部服務，並帶入對應的 header 該怎麼做？"},"/docs/nginx/soketi-log-502-error/":{"data":{"":"此文章要來記錄一下 RD 同仁前陣子有反應使用 Soketi 這個 WebSocket Server 會不定時在 LOG 出現 502 error 錯誤訊息以及 connect() failed (111: Connection refused) while connecting to upstream，雖然說服務使用上不會影響很大，但還是希望我們可以協助找出 502 的原因。\n出錯的 LOG 在開始找問題前，先簡單介紹一下 Soketi 是什麼東西好了，根據官網的說明，他是簡單、快速且有彈性的開源 WebSockets server，想要了解更多的可以到它官網去查看。\n另外會把程式碼相關放到 GitHub » 點我前往","參考#參考":"[Nginx] 解決 connect() failed (111: Connection refused) while connecting to upstream：https://wshs0713.github.io/posts/8c1276a7/\nWebSocket proxying：http://nginx.org/en/docs/http/websocket.html\nday 10 Pod(3)-生命週期, 容器探測：https://ithelp.ithome.com.tw/articles/10236314","壓測#壓測":"最後調整完，我們來測試看看是否在 Pod 自動重啟 or 更新 Deployment 的時候(並且有大量連線時)還會噴 502 error 或是 connect() failed (111: Connection refused)，我們這邊使用 k6 來做 websocket 服務的壓測，有簡單寫一個壓測程式如下：\nk6 壓測\nk6 是一個開源的壓測工具，可以用來測試 API、WebSocket、gRPC 等服務，可以到它的官網查看更多資訊。\nMacOS 安裝方式：brew install k6\nwebsocket.jsimport ws from \"k6/ws\"; import { check } from \"k6\"; export const options = { vus: 1000, duration: \"30s\", }; export default function () { const url = \"wss://socket.XXX.com/app/hex-ws?protocol=7\u0026client=js\u0026version=7.4.1\u0026flash=false\"; const res = ws.connect(url, function (socket) { socket.on(\"open\", () =\u003e console.log(\"connected\")); socket.on(\"message\", (data) =\u003e console.log(\"Message received: \", data)); socket.on(\"close\", () =\u003e console.log(\"disconnected\")); }); check(res, { \"status is 101\": (r) =\u003e r \u0026\u0026 r.status === 101 }); } 簡單說明一下上面程式在寫什麼，我們在 const 設定 vus 代表有 1000 個虛擬使用者，會在 duration 30s 內完成測試，下面的 default 就是測試連線 ws 以及 message 跟 close 等動作，最後需要回傳 101 (ws 交握)\n執行 k6 run websocket.js 後，就會開始壓測，可以看到會開始執行剛剛在上面提到 default 的動作：\nk6 壓測過程 等到跑完，就會告訴你 1000 筆裡面有多少的 http 101，這邊顯示 status is 101，就代表都是 101，代表都有連線成功，沒有出現 502 error 或是 connect() failed (111: Connection refused) 的錯誤，這樣就代表我們的問題解決了。\nk6 壓測結果 ","解決過程#解決過程":"我們可以看到上方錯誤 LOG 中，發現有出現 502 error 以及 connect() failed (111: Connection refused) while connecting to upstream，這兩個錯誤都是由 Nginx 所產生的，那我們先來理解一下，Nginx 與 Soketi 之間的關係。\n在使用上，RD 的程式會打 Soketi 專用的 Subdomain 來使用這個 WebSocket 服務，而在我們的架構上，這個 Subdomain 會經過用 nginx proxy server，來轉發到 Soketi WebSocket Server (走 k8s svc)，設定檔如下圖：\n入口 nginx 設定 然後會出現 connect() failed (111: Connection refused) while connecting to upstream 的錯誤訊息，代表我們的 Nginx 設定少了一個重要的一行設定，就是 proxy_http_version 1.1;，這個設定要讓 Nginx 作為 proxy 可以和 upstream 的後端服務也是用 keepalive，必須使用 http 1.1，但如果沒有設定預設是 1.0，也要記得設定 proxy_set_header Upgrade、proxy_set_header Connection。調整過後就變成：\nws.confserver { server_name socket.XXX.com; listen 80 ; listen [::]:80 ; listen 443 ssl; listen [::]:443 ssl; ssl_certificate /etc/nginx/ingress.gcp.cert; ssl_certificate_key /etc/nginx/ingress.gcp.key; access_log /var/log/nginx/access.log main; location / { proxy_pass http://soketi-ws-ci:6001; proxy_connect_timeout 10s; proxy_read_timeout 1800s; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"Upgrade\"; proxy_set_header X-Real-IP $remote_addr; } } 解決完 connect() failed (111: Connection refused) 這個問題後，接下來就是要解決 502 error 這個問題，會導致 502 代表 Nginx 這個 proxy server 連不上後端的 Soketi WebSocket Server，再觀察 LOG 以及測試後發現，當 Pod 自動重啟，或是手動重啟 Deployment 的時候，就會有 502 的錯誤，代表 Nginx 在 proxy 到後面的 Soketi svc 再到 Pod 的時候，有一段時間是連不上的，所以就會出現 502 的錯誤，可以推測是流量進到正在關閉的 Pod 或是進到還沒有啟動好的 Pod 才導致的。\n那我們先來看一下 Soketi WebSocket Server 的服務 yaml 檔案：\ndeployment.yaml deployment.yaml spec: terminationGracePeriodSeconds: 30 securityContext: {} containers: - name: soketi securityContext: {} image: \"quay.io/soketi/soketi::1.6.0-16-alpine\" ... 省略 (可以到 github 看 code)... livenessProbe: failureThreshold: 3 httpGet: httpHeaders: - name: X-Kube-Healthcheck value: \"Yes\" path: / port: 6001 initialDelaySeconds: 5 periodSeconds: 2 successThreshold: 1 可以看到原來的設定只有 livenessProbe 而已，因此我們為了要避免流量進到正在關閉的 Pod 或是進到還沒有啟動好的 Pod，所以我們需要加上 readinessProbe 以及 preStop，讓 Pod 確定啟動完畢，或是等待 Service 的 endpoint list 中移除 Pod，才開始接收流量，這樣就可以避免出現 502 的錯誤。\ndeployment.yaml spec: terminationGracePeriodSeconds: 30 securityContext: {} containers: - name: soketi securityContext: {} image: \"quay.io/soketi/soketi::1.6.0-16-alpine\" ... 省略 (可以到 github 看 code)... livenessProbe: failureThreshold: 3 httpGet: httpHeaders: - name: X-Kube-Healthcheck value: \"Yes\" path: / port: 6001 initialDelaySeconds: 5 periodSeconds: 2 successThreshold: 1 readinessProbe: failureThreshold: 3 httpGet: httpHeaders: - name: X-Kube-Healthcheck value: \"Yes\" path: /ready port: 6001 initialDelaySeconds: 5 periodSeconds: 2 successThreshold: 1 lifecycle: preStop: exec: command: [\"/bin/sh\", \"-c\", \"sleep 20\"] Pod 終止的過程 "},"title":"Soketi WebSocket Server LOG 不定時出現 502 error 以及 connect() failed (111: Connection refused)"},"/docs/opentelemetry/":{"data":{"":"Explore the following sections to learn how to use Hextra:\n如何透過 OpenTelemetry 來收集 Ingress Nginx Controller 的 Metrics 與 Traces 並送到 Datadog 上 "},"title":"Opentelemetry"},"/docs/opentelemetry/opentelemetry-ingress-nginx-controller/":{"data":{"":"由於最近公司想要導入 Datadog，在測試過程中順便導入 OpenTelemetry 來收集 Metrics 與 Traces 並送到 Datadog 上 ～\n🔥 這個範例比較特別，因為 Datadog 有提供 Ingress Nginx Controller 的 integrations，可以透過 Datadog Agent 來收集 Metrics，不需要透過 OpenTelemetry Collector 來收集。 ( Datadog Agent 請參考：https://docs.datadoghq.com/containers/kubernetes/ )\n程式部分也同步上傳到 github 上，可以點我前往","參考#參考":"Configure Nginx Ingress Controller to use JSON log format：https://dev.to/bzon/send-gke-nginx-ingress-controller-logs-to-stackdriver-2ih4\n淺談 OpenTelemetry - Collector Compoents：https://ithelp.ithome.com.tw/articles/10290703","執行步驟#執行步驟":" 先 clone 這個 repo (廢話 xD)\n先建立 OpenTelemetry Collector，執行以下指令：\nhelm upgrade collector \\ opentelemetry-collector \\ --repo https://open-telemetry.github.io/opentelemetry-helm-charts \\ --install \\ --create-namespace \\ --namespace opentelemetry \\ -f \"otel-collector.yaml\" 再建立 Ingress Nginx Controller，執行以下指令：\nhelm upgrade ingress-nginx \\ ingress-nginx \\ --repo https://kubernetes.github.io/ingress-nginx \\ --install \\ --create-namespace \\ --namespace ingress-nginx \\ -f \"ingress-nginx-values.yaml\" 接著建立測試用 Nginx 服務，執行以下指令：\nkubectl apply -f nginx.yaml ","檔案說明#檔案說明":" otel-collector.yaml： OpenTelemetry Collector 的設定檔，主要是設定要收集哪些 metrics、traces，並且要送到哪個 exporter，要注意的是 exporters 的 datadog 需要設定 site、api_key，以及 image 要記得用 otel/opentelemetry-collector-contrib，才會有 datadog 的 exporter。\ningress-nginx-values.yaml： Ingress Nginx Controller 的設定檔，這邊的 podAnnotations 是為了讓 Ingress Nginx Controller 的 Pod 能夠透過 Datadog agent 收集 metrics 到 Datadog 才加上的。\nconfig 裡面的設定有很多，主要都是 openTelemetry 的設定，要注意的是 enable-opentelemetry 要設為 true，另外 otlp-collector-host 以及 otlp-collector-port 要送到哪個 collector 等等也要記得設定。 另外如果想要將 LOG 與 Trace 串再一起，記得要把 log-format 設為 json，並且帶入，trace_id 與 span_id ( 這邊有多帶 dd.trace_id 是為了讓 datadog 可以自動串接 LOG \u0026 Trace )。\nnginx.yaml： 一個簡單的 Nginx 整套服務 (Deployment、Service、Ingress)，要注意的是 Ingress 需要設定 annotations kubernetes.io/ingress.class: nginx (這個是 Ingress Nginx Controller 的預設 class name)，才會被 Ingress Nginx Controller 接管 (才會有 Load Balancer 的 IP)","測試#測試":"當你執行完上面的步驟後，你會發現有產生兩個 namespace，一個是 ingress-nginx，另一個是 opentelemetry，並且會有 OpenTelemetry Collector、Ingress Nginx Controller、Nginx 等服務，如下：\n啟動服務 我們試著打 http://nginx.example.com/ (測試網址，需要先在 /etc/hosts 綁定 Ingress Nginx Controller 咬住的 Load Balancer IP)，查看一下 Datadog 的 LOG，看看是否有收到 Nginx 的 LOG (此收集 LOG 的方式是透過在 cluster 上安裝 Datadog 的 agent)，如下：\nDatadog LOG 接著查看 Datadog APM 的 trace，如下：\nDatadog APM 由於我們在後面目前沒有串其他服務，所以只有一個 span，之後還有另外兩篇文章是介紹如何串其他服務 (會增加服務以及部分設定)，可以參考看看：opentelemetry-roadrunner、opentelemetry-nodejs\n順便看一下透過 Datadog Agent 收集的 Ingress Nginx Controller 的 Metrics，如下：\nDatadog Ingress Nginx Controller 的 Metrics 可以用這些 Metrics 來做 Dashboard，如下：\nDatadog Dashboard ","結論#結論":"透過 OpenTelemetry Collector 來收集 Ingress Nginx Controller 的 Metrics 與 Traces 並送到 Datadog 上，這樣就可以透過 Ingress Nginx Controller 的 Metrics 來做監控了，對於 RD 再開發上，有 Traces 也更方便 RD 他們找到程式的瓶頸 (有可能是服務導致的)。"},"title":"如何透過 OpenTelemetry 來收集 Ingress Nginx Controller 的 Metrics 與 Traces 並送到 Datadog 上"},"/projects/":{"data":{"":" 活動申請系統 (Web) "},"title":"專案成就"}}